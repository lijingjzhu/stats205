---
title: 'STATS 205: The Washington Post Data Validation'
author: "Julie Zhu"
date: "May 19, 2016"
output:
  html_document:
    toc: true
    number_sections: true
    theme: spacelab
    tango: true
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

# Introduction

The goal of this study is to examine the dataset we have from The Washington 
Post. We want to do quick data validation for the Washington Post and get rid 
of funky entries. Then, we want to look at the results from the two data sets individually and compare the two. 

We will first load in our libraries and our data. We obtain our gender and 
population data from the census: https://www.census.gov/popest/data/index.html

In the data, we have:

* Renamed values to be consistent across datasets
* Removed NA values
* Performed quick data visualization and demographics

For our data, we used `The Washington Post` data from 2015. 

```{r}
# Libraries
library(ggplot2)
library(purrr)
library(readr)
library(lubridate)
library(tidyr)
library(dplyr)
library(stringr)
library(datasets)

# Parameters
file_out <- "data/washington_police.csv"
washington_file <- "data/washington_post.csv"
population_file <- "data/population.csv"
race_file <- "data/race_and_ethnicity.csv"

# Reading in data
washington <- read_csv(washington_file)
population <- read_csv(population_file, col_names = TRUE)
ethnicity <- read_csv(race_file, col_names = TRUE)
```

# Understanding the Data

We will first take a look at `The Washington Post`'s police killings dataset by 
itself before we join with the `police_killings` data. We want to understand 
the missing values as well as the size of the data. 

The dataset has 1,357 observations and 14 variables. We have more observations 
and different predictors, however, than the Guardian data.

```{r}
dim(washington)
```

Looking at the summary, we see the date is in a different format than the one 
found in `The Guardian` data set. We also see that now we have variables that 
mean the same thing, but have different factors and variable names. For example,
`manner_of_death` is equivalent to the `classification` column in `The Guardian` 
data set. There are also slightly different levels. 

Some new variables include `signs_of_mental_illness`, `flee`, and `body_camera`. 

```{r}
summary(washington)
```

One of the first things we notice is that there aren't many null values (`r sum(is.na(washington))`). 

We will first categorize unknown ages to nulls.

```{r}
washington <- washington %>%
  mutate(age = ifelse(age == "Unknown", NA, as.numeric(age)))
```

One annoying feature we might have to replace is the race column. We have just 
letters for the races and we are unsure what these represent. The data nor the 
website specifies what the codes mean. We can try to match the individuals and 
make our best guess.

```{r}
levels(factor(washington$race))
```

We also see that there are less levels for manner of death than there are for 
`The Guardian` data set. We see that there are only two factors: shot or shot 
and tasered. Clearly not all deaths of the victims in police are due to these 
two causes. Once we combine, we will see that there will be quite a few 
discrepencies. 

```{r}
levels(factor(washington$manner_of_death))
```

## Renaming Gender

Gender in the `Washington Post` data comes in two categories: male and female. However, they are coded slightly differently. 

```{r}
table(washington$gender)
```

We will try to rename the gender variable to that it matches with the genders 
in the other data set. 

```{r}
washington$gender[washington$gender == "M"] <- "Male"
washington$gender[washington$gender == "F"] <- "Female"
```

## Null Values

We also want to explore null values in the data set and perhaps determine if 
there are any patterns. First we set all unknown values to null, since the 
null isn't already included in the data set.

We see that there are 135 total null values in the data. 

```{r}
sum(is.na(washington))
```

## Renaming Armed

There are a lot more factors for armed than there are for `The Guardian` 
dataset. We will try to map the Washington Post data set to the Guardian data 
set. We see that some of the categories line up exactly like knife, vehical, 
firearm (gun), and unarmed. However, some of them don't quite line up. We will
categorize the ones who don't quite fit (undetermiend and unknown) into the 
Disputed category. 

```{r}
non_lethal_firearms <- c("nail gun", "toy weapon", "bean-bag gun")
firearms <- c("hand torch", "gun and knife","gun", "guns and explosives")
knives <- c("ax", "box cutter", "knife", "hatchet", "machete", 
            "lawn mower blade", "meat cleaver", "scissors", 
            "straight edge razor", "sword")
counted_armed <- c("No", "Vehicle", "Disputed", "Knife", 
                   "Non-lethal firearm", "Firearm")

washington <- washington %>%
  mutate(armed = ifelse(armed == "unarmed", "No", armed),
         armed = ifelse(armed == "vehicle", "Vehicle", armed),
         armed = ifelse(armed == "undetermined", "Disputed", armed),
         armed = ifelse(armed %in% knives, "Knife", armed),
         armed = ifelse(armed %in% non_lethal_firearms, "Non-lethal firearm", armed),
         armed = ifelse(armed %in% firearms, "Firearm", armed),
         armed = ifelse(!(armed %in% counted_armed), "Other", armed))
```

## Renaming Race

We also notice that the race codes are a little different across the two data 
sets. However, we see that there are the same levels for the race predictor. 
The first letter of each race from `The Guardian` data set actually matches 
each letter code from `The Washington Post` data set. We do a quick 
transformation to change the races. This could be a source of error since
we don't have the exact metadata.

```{r}
washington <- washington %>%
  mutate(race = ifelse(race == "A", "Asian/Pacific Islander", race),
         race = ifelse(race == "B", "Black", race),
         race = ifelse(race == "H", "Hispanic/Latino", race),
         race = ifelse(race == "N", "Native American", race),
         race = ifelse(race == "O", "Other", race),
         race = ifelse(race == "W", "White", race))
```

## Final Dimensions

We end up with 1357 observations. 

```{r}
dim(washington)
```

# Descriptive Statistics

In this section, we hope to explore the distribution of some variables by 
visualizing them using plots. This is the same analysis as in the 
`1_counted_data.Rmd` file, but with the Washington Post data. 

## Age

First, we look at age. We make a simple histogram and we see that the 
distribution of ages is somewhat right-skewed. We have a couple of minors 
killed by police and some elderly. Most police killing victims are middle aged. 
This matches the results we did in our previous study.

```{r, fig.width = 4, fig.height = 4}
washington %>%
  filter(!is.na(age)) %>%
  ggplot() +
  geom_histogram(mapping = aes(x = age), binwidth = 5) +
  labs(x = "Age", y = "Count")
```

## Gender

Before normalization, we see that there is an extreme gender disparity in those 
killed by the police. Men are overwhelming killed more so than women. This 
is expected. 

```{r, fig.width = 4, fig.height = 4}
washington %>%
  filter(!is.na(gender)) %>%
  ggplot() +
  geom_bar(mapping = aes(x = gender)) +
  labs(x = "Gender", y = "Count")
```

## Ethnicity

Going off of raw counts, we see that there are more white and black victims 
than the rest of the ethnicities combined. There are some missing values, so 
we filter those out first. Here, we actually see that there are fewer Native 
American victims than Other victims, something a little different than in the 
other data set. 

```{r, fig.width = 4, fig.height = 4}
washington %>%
  filter(!is.na(race)) %>%
  count(race) %>%
  ggplot() +
  geom_bar(mapping = aes(x = reorder(race, -n), y = n), 
           stat = "identity") +
  labs(x = "Ethnicity", y = "Count") +
  theme(axis.text.x = element_text(angle = 35, hjust = 1))
```

## Normalized Ethnicity

Normalizing for the ethnic breakdown in the population, we get a result that 
is quite different. We first wrangle the ethnicity data so that we have nicer 
race names and the like. We also combine Asian and Pacific Islander in our 
ethnicity data so that it matches the race and ethinicites we have in our 
`police_killings` data. 

```{r}
total_pop <- ethnicity[2, 4] %>% as.numeric()
ethnicity <- ethnicity[,c(3, seq(6, 26, by = 2))] 

race_names <- c("state", "Total", "White", "Black", "Native American", "Asian", "Pacific Islander", "Other", "Other1", "Other2", "Other3", "Hispanic/Latino")
colnames(ethnicity) <- race_names

ethnicity <- ethnicity[-1,]

total_race <- ethnicity %>%
  dmap_at(race_names[2:length(race_names)], as.numeric) %>%
  mutate(county = lapply(str_split(state, ","), '[[', 1) %>% unlist(),
         state = lapply(str_split(state, ","), '[[', 2) %>% unlist(),
         Other = Other + Other1 + Other2 + Other3,
         `Asian/Pacific Islander` = Asian + `Pacific Islander`,
         county = tolower(county),
         state = trimws(state)) %>%
  select(-c(Other1, Other2, Other3, Asian, `Pacific Islander`)) %>%
  group_by(state) %>%
  summarise(White = sum(White),
            Black = sum(Black),
            `Native American` = sum(`Native American`),
            `Asian/Pacific Islander` = sum(`Asian/Pacific Islander`),
            Other = sum(Other),
            `Hispanic/Latino` = sum(`Hispanic/Latino`)) %>%
  ungroup() %>%
  gather(race, pop, White:`Hispanic/Latino`) %>%
  group_by(race) %>%
  summarise(pop = sum(pop))
```

After normalizing for ethnicity, we see that the proportion of black victims 
killed is almost twice as if they were to randomly sample people off the street.
Hispanic and Native American are second. We see that White, Other, and Asian 
victims are less likely to be killed. 

```{r, fig.width = 5, fig.height = 4}
washington %>%
  count(race) %>%
  filter(!is.na(race)) %>%
  left_join(total_race, by = c("race" = "race")) %>%
  mutate(prop = (n/pop)*100000) %>%
  ggplot() +
  geom_bar(mapping = aes(x = reorder(race, -prop), y = prop), 
           stat = "identity") +
  labs(x = "Ethnicity", y = "Number of Ethnic Race Killed per 100,000") +
  theme(axis.text.x = element_text(angle = 35, hjust = 1)) 
```

## Armed

Next, we examine whether the victims were armed. Firearms are the most common 
form of armed victims. However, interestingly enough, we see that there are 
also a lot of unarmed victims that were shot as well. 

```{r, fig.width = 5, fig.height = 4}
washington %>%
  count(armed) %>%
  top_n(15) %>%
  ggplot() +
  geom_bar(mapping = aes(x = reorder(armed, -n), y = n), 
           stat = "identity") +
  labs(x = "Armed", y = "Count") +
  theme(axis.text.x = element_text(angle = 35, hjust = 1))
```

## Classification

Most of the victims that the police killed were killed by a gunshot. For 
those who are shot and tasered pale in comparison frequency wise. However, 
it seems like there are only two ways a victim died by police. 

```{r, fig.width = 4, fig.height = 4}
washington %>%
  count(manner_of_death) %>%
  ggplot() +
  geom_bar(mapping = aes(x = reorder(manner_of_death, -n), y = n), 
           stat = "identity") +
  labs(x = "Death Classification", y = "Count") +
  theme(axis.text.x = element_text(angle = 35, hjust = 1))
```

## State

Looking at state, we see that with raw deaths, California takes the cake with 
over 150 police killings. Rounding out the top 5 we have California, Texas, 
Florida, Arizona, and Colorado.

```{r, fig.width = 5, fig.height = 4}
washington %>%
  count(state) %>%
  top_n(10) %>%
  ggplot() +
  geom_bar(mapping = aes(x = reorder(state, -n), y = n), 
           stat = "identity") +
  labs(x = "State", y = "Count") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

## Normalized by Population State

Once we normalize the number of people killed, we see that the state rankings 
are quite different. 

We first wrangle the `state` data into a useable form. 

```{r}
data(state)

state_info <- data_frame(state_name = state.name,
                    state_abb = state.abb)

colnames(population) <- c(seq(1, ncol(population)))

population <- population[9:59, ] %>%
  select(1, 9) %>%
  rename(state = `1`,
         pop = `9`) %>%
  mutate(state = str_replace(state, ".", "")) %>%
  left_join(state_info, by = c("state" = "state_name")) %>%
  select(-state)
```

We filter out DC since we don't have a population estimate for DC. Rounding 
out the top five, we have Oklahoma, Arizona, Colorado, Louisiana, and 
California. 

A potential route to go here is to see if the ranking of the states is 
statistically significant from the ranking of the states by proportion of 
Black populations. 

```{r, fig.width = 5, fig.height = 4}
washington %>%
  count(state) %>%
  top_n(10) %>%
  left_join(population, by = c("state" = "state_abb")) %>%
  filter(!(state == "DC")) %>%
  mutate(pop_pct = n/pop*100000) %>%
  ggplot() +
  geom_bar(mapping = aes(x = reorder(state, -pop_pct), y = pop_pct), 
           stat = "identity") +
  labs(x = "State", y = "Number of State Killed per 100,000") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

## Month

Lastly, we look at the time of the killings. We use the month to track the 
number of killings across the year. We see that this trend is slightly 
different from the one we obtained with the Guardian data set. We see the peak 
in `The Guardian` data set is in March, but this one has the peak in around 
February. The largest dip ends in June, which matches the other data set, has 
a local peak in August, and drifts off for the rest of the year. 

```{r, fig.width = 6, fig.height = 4}
washington %>%
  dmap_at("date", ymd) %>%
  mutate(month = month(date)) %>%
  count(month) %>%
  ggplot() +
  geom_line(mapping = aes(x = factor(month), y = n), stat = "identity",
            group = 1) +
  labs(x = "Month", y = "Count") +
  theme(axis.text.x = element_text(angle = 30, hjust = 1)) +
  scale_x_discrete(labels = c("January","February","March","April", "May", 
                              "June", "July", "August", "September",
                              "October", "November", "December"))
```

We might want to look at February deaths in this data set a little more closely.

# Next Steps 

Next steps would be to proceed to join the two data sets together to see if 
there are any observations that agree. Then we can confirm those observations 
and carefully vet through the observations with discrepancies to make our 
data set. 

## Writing Out Data

Finally, we can write out our edited data to a new file so that we can load 
it in quickly for our next study. Since we got rid of the null values, we can 
output the new data into `washington_police.csv`.

```{r}
washington <- washington %>%
  dmap_at("date", ymd) 

write_csv(x = washington, path = file_out)
```